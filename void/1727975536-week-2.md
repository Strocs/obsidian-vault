---
id: 1727975536-week-2
aliases:
  - Week 2
tags:
  - google
  - cloud
  - course
  - notes
---

# Week 2

## Video

planning and configuring cymbal syperstone cloud solutions

1. planning and estimating gc pricing using calculator
planning and confirugirn compute resources
planning and cong data storagte otions
network resources

Ecommerce app
transportation management
suppl chain


# Lab: Set Up an App Dev Environment on Google Cloud

## Cloud Storage: Qwik Start - Cloud Console

#### Create a storage bucket
  1. **Navigation** > **Cloud Storage** > **Buckets**
  2. **Create**
    - Unique name
      - Not include sensitive information
      - Lowercase letters, numbers, dashes, underscores and dots. (dots require verifications)
      - Must start and end with a number or letter
      - 3 to 63 characters
      - Cannot be an IP address like
      - Cannot start with "goog" prefix, and cannot contain "google" or a close misspelling of "google"
      - Is not recommended use underscores, because DNS compliance and future compatibility

#### Upload objects to the bucket
  - Click on **bucket** created
  - **Objects** tab > **Upload files**
  - Object name must be unique only in the bucket context

#### Make objects in a storage bucket publicly accessible
  - Click on **Permissions** tab inside the bucket created
  - view must be set on **Principals**
    - **Grant Access** to view **Add principals** pane 
    - **New principals** input, select or write **allUsers** 
    - In **Select a role** dropdown: **Cloud Storage** > **Storage Object Viewer**    
    - Click **Save**
    - **Allow public access** 
  - **Verify:** 
    - In  Object's **Public access** should read **Public to internet** 
    - **Copy URL** and verify in browser 

#### Create folders and subfolders in the bucket
  - Create a folder and subfolder
    - **Objects** tab > **Create folder**
      - Should see a folder in the bucket with an folder icon that distinguish it from objects
    - Create a subfolder
      - Click on the folder created
      - **Create folder**   
  - Delete a folder
    - Return to bucket level
    - Select the bucket and click **Delete** button
    - Type _DELETE_ to confirm

## Cloud Storage: Qwik Start - CLI/SDK

> [!NOTE]
> Is important to set thge default region before creating a bucket
> ```bash
> gcloud config set compute/region us-central1
> ```

#### Create a storage bucket
  -  Creating a [[1729179788-bucket|bucket]] using the [[1729179907-cli|CLI]]
    - `gsutil mb gs://<bucket-name>`
    - mb means _make bucket_
    - Create a bucket with default settings

#### Upload objects to the bucket
  - uploading a object using the [[1729179907-cli|CLI]]
    - We can download the image into de bucket with a curl command `curl <file-url> --output <file-name> `   
    - Then copy into the bucket `gsutil cp <file-path> gs://<bucket-name>`
    - Then delete the downloaded image with `rm <file-name>`

#### Download an object from the bucket
  - `gsutil cp -r gs://<bucket-name>/<object-name> <local-path>`

#### Copy an object from one bucket to another
  - `gsutil cp gs://<bucket-name>/<object-name> gs://<bucket-name>/<object-name>`

#### List objects in a bucket
  - `gsutil ls gs://<bucket-name>`

#### List details for an object
  - `gsutil ls -l gs://<bucket-name>/<object-name>`

#### Make objects in a storage bucket publicly accessible
  - `gsutil acl ch -u AllUsers:R gs://<bucket-name>/<object-name>`
  - ACL means _access control list_

#### Remove public access
  - `gsutil acl ch -d AllUsers gs://<bucket-name>/<object-name>`
  - Delete an object with `gsutil rm gs://<bucket-name>/<object-name>`

## Cloud IAM: Qwik Start

> [!NOTE]
> Login with two different accounts to explore how granting and revoking permissions works

#### Explore the [[1729180020-iam|IAM]] console and project level roles
  - On _Username 1_
    - **Navigation menu** > **IAM & Admin** > **IAM**    
    - **+GRANT ACCESS** 
    - **Basic** in Select a role 
      - Three roles: **Editor**, **Viewer** and **Owner**
      - This are **Primitive roles** that are project-level permissions, that meas they control access and management to all GC services.
        ![Basic roles and permissions](files/gc-roles-permissions.png)
  - On _Username 2_
    - **Navigation menu** > **IAM & Admin** > **IAM**
    - We can see the different permissions assigned to username 1 and username 2, if with username 2 we try to **Grant Access** we get an _need permissions_ error message. 

#### Prepare a Cloud Storage bucket for access testing
  - Create a [[1729179788-bucket|bucket]] from from [[1729179755-google-cloud-console|Google Cloud Console]]   
    - Region: Multi-Region
  - Upload a sample file
    - Any txt or html file from computer
    - Rename object to: sample.txt

#### Remove project access
  - On _Username 1_
    - **Navigation menu** > **IAM & Admin** > **IAM**
    - Click the trashcan icon next to the role name of Username 2, then **save** 
    - On _Username 2_
    - **Navigation menu** > **Cloud Storage** > **Buckets**
    - Should see and permission error message
#### Add Cloud Storage permissions
  - Copy _Username 2_ name
  - On _Username 1_
    - **Navigation menu** > **IAM & Admin** > **IAM**
    - **GRANT ACCESS** and paste _Username 2_ name into **New principals** 
    - **Select a role** dropdown select **Cloud Storage** > **Storage Object Viewer**   
  - Verify access
    - On _Username 2_
      - This user doesnt not have aproject viewer role, so cant see the project or any of its resources in the [[1729179755-google-cloud-console|Console]]
      - However, has specific access to [[1729180741-cloud-storage|Cloud Storage]]
        - Listing the buckets we can see the sample.txt object

## Cloud Monitoring: Qwik Start
> [!NOTE]
> Set default zone and region

#### Create a Compute Engine instance
  - **Navigation menu** > **Compute Engine** > **VM instances**
  - **Create instance**

#### Add Apache2 HTTP Server to your instance
  - From shell
    - `sudo apt-get update`
    - `sudo apt-get install apache2 php7.0`
    - `sudo service apache2 restart`
  - Create a Monitoring Metrics Scope
    - **Navigation menu** > View All Products > **Observability** > **Monitoring** 
    - When the **Overview** page laods, metrics scope are ready
  - Install the Monitoring and Logging agents
     > By default, monitoring agent collect, disk, CPU, network and process metrics. 

     > [!NOTE]
     > Its best practice to run the logging agent on all vm instances
    - On the SSH terminal of the instance
      -  Monitoring agent install script
        - `curl -sSO https://dl.google.com/cloudagents/add-google-cloud-ops-agent-repo.sh`
        - `sudo bash add-google-cloud-ops-agent-repo.sh --also-install`
      - Logging agent install script
        - `sudo systemctl status google-cloud-ops-agent"*"`
        - `sudo apt-get update`

#### Create an uptime check
  > [!NOTE]
  > This step could take more time to complete, so we can do the next steps while the uptime check is running
  - **Uptime checks** > **Create uptime check**
    - Protocol: HTTP
    - Resource type: Instance
    - Check frecuency: 1 minutes

#### Create an alerting policy
  - **Alerting** > **Create policy**
    - Uncheck **Active** on Select a metric 
    - type **Network traffic** in filter
    - Select `Network traffic` in **VM instajce** > **Interface**  
    - **Threshold position** to `Above threshold` 
    - **Threshold value** to `500`
    - **Advance Options** > **Retest window** to `1 min`  
  - On **Notificacion Channels** > **Manage Notification Channels**  
    - **ADD NEW** > **Email**
    - **Create Email Channel** > add email address and display name 
  - **Alert name** as `Inbound Traffic Alert`

#### Create a dashboard and chart
  - **Navigation menu** > **Monitoring** > **Dashboards**
  - **Create dashboard**
  - Add a chart
    - **ADD WIDGET** 
    - **Line**  option
    - Uncheck **Active** on Select a metric

#### View tour logs
  - **Navigation menu** > **Logging** > **Logs Explorer**
  - Select logs for the instance created
    - Click on **Resource** 
    - Select **VM Instance** > **Instance name**
    - **Apply** 
    - **Stream logs** 
  - Must see logs for the VM instance

#### Check the uptime check results and triggered alerts
  - **Navigation menu** > **Monitoring** > **Uptime checks**
  - This will show the uptime check listed
  - Check if alerts have been triggered
    - Click on **Alerting**
    - This will show incidents and events listed

## Cloud Functions: Qwik Start - Console
> [!NOTE]
> A cloud function is a piece of code that runs in response to an event like a HTTP request, a message from a messaging service, or a file upload.

#### Create a function
  - **Navigation menu** > **Serverless** > **Cloud Run Functions**
  - **Create Function**
    - Enviornment: Cloud Run function
    - Triger Type: HTTP
    - Allow unauthenticated invocations
#### Deplot the function
  - Use the default `helloWorld` function
  - Click on **Deploy**

#### Test the function
  - On the **Overview** page click on the function name
  - Click on **Testing**

#### View logs
  - on the actions menu click on **View Logs**
  - This will show the logs for the function like **Query results** 


## Cloud Functions: Qwik Start - Command Line

> [!NOTE]
> The event for this section will be a pub/sub message. A pub/sub is a messaging service where the sender are decoupled from the receivers. When a message is sent or posted is required a subscription to it to be alerted and receive the message.

#### Create a function
  - Set Region 
  - Create a directory for the function 
  - Create and open the index.js file
  - Crete the function
  - Create and open the package.json file
  - Install the dependencies
  ```js
  const functions = require('@google-cloud/functions-framework');
  
  // Register a CloudEvent callback with the Functions Framework that will
  // be executed when the Pub/Sub trigger topic receives a message.
  functions.cloudEvent('helloPubSub', cloudEvent => {
    // The Pub/Sub message is passed as the CloudEvent's data payload.
    const base64name = cloudEvent.data.message.data;
  
    const name = base64name
      ? Buffer.from(base64name, 'base64').toString()
      : 'World';
  
    console.log(`Hello, ${name}!`);
  });
```

#### Deploy the function
  - The trigger must be specified, like `--trigger-topic`, `--trigger-bucket` or `--trigger-http` are commonly used
  - In this case we will use `--trigger-topic` for a pub/sub called `cf-demo`
    ```bash
    gcloud functions deploy nodejs-pubsub-function \
      --gen2 \
      --runtime=nodejs20 \
      --region=REGION \
      --source=. \
      --entry-point=helloPubSub \
      --trigger-topic cf-demo \
      --stage-bucket PROJECT_ID-bucket \
      --service-account cloudfunctionsa@PROJECT_ID.iam.gserviceaccount.com \
      --allow-unauthenticated
    ```
  - Verify the status of the function
    - `gcloud functions describe <function-name> --region=REGION`

#### Test the function
  - Invoke the pub/sub `gcloud pubsub topics publish <topic-name> --message="Cloud Function Gen2"`

#### View logs
  - `gcloud functions logs read <function-name> --region=REGION`
  > [!NOTE]
  > Log can take a long time to show up, we can use the console to view the logs


## Pub/Sub: Qwik Start - Console
  > [!NOTE]
  > Pub/Sub is a messaging service for exchanging event data between applications. A producer of data publishes messages to a Pub/Sub topic, and a consumer, that must be subscribed to that message, receive the data message.

#### Setting up [[1729211457-pub-sub|Pub/Sub]]
  - First create a topic to hold data and subscriptions
    - **Navigation menu** > **Pub/Sub** > **Topics**
    - **Create topic**
      - Must have an unique name
  
#### Add a subscription
  - On **Topic** page > Three dots > **Create subscription** 
  
#### Publish a message to the topic 
  - **pub/sub** > **Topics** and open `<topic-name>` page  
  - Clicn on **Messages** tab > **Publish message**
  -  Set a message

#### View the message
  - We have to pull the ,message from the topic
    - `gscould pubsub subscriptions pull --auto-ack <subscription-name>`

## Pub/Sub: Qwik Start - Command Line

#### Pub/Sub topics
  - Create a topic `gcloud pubsub topics create <topic-name>`
  - List topics `gcloud pubsub topics list`
  - Delete a topic `gcloud pubsub topics delete <topic-name>`

#### Pub/Sub subscriptions
  - Create a subscription `gcloud pubsub subscriptions create --topic <topic-name> <subscription-name> `
  - List subscriptions `gcloud pubsub subscriptions list`
  - Delete a subscription `gcloud pubsub subscriptions delete <subscription-name>`

#### Pub/Sub publishing and pulling a single message
  - Publish a message `gcloud pubsub topics publish <topic-name> --message="Hello World"`
  - Pull a message `gcloud pubsub subscriptions pull <subscription-name> --auto-ack`
    - With pull just one message is shown

### Pub/Sub pulling all messages from subscriptions 
  - Pull all messages `gcloud pubsub subscrptions pull <subscription-name> --auto-ack --limit=3`

## Pub/Sub: Qwik Start - Python

#### Create a virtual environment
  - Install virtualenv `sudo apt-get install -y virtualenv`
  - Build the env `python3 -m venv venv`
  - Activate the env `source venv/bin/activate`

#### Install the client library
  - Install client `pip install --upgrade google-cloud-pubsub`
  - Get sample code `git clone https://github.com/googleapis/python-pubsub.git`
  - Change directory `cd python-pubsub/samples/snippets`

#### Create a topic
  - Set Project ID in the env variable `echo $GOOGLE_CLOUD_PROJECT`
  - `publisher.py` is a script that perform basic operations on topics with the Cloud Pub/Sub API
  - Create a topic `python publisher.py $GOOGLE_CLOUD_PROJECT create <topic-name>`
  - List topics `python publisher.py $GOOGLE_CLOUD_PROJECT list`

#### Create a subscription
  - Create a subscription `python subscriber.py $GOOGLE_CLOUD_PROJECT create <topic-name> <subscription-name>`
  - List subscriptions `python subscriber.py $GOOGLE_CLOUD_PROJECT list-in-project`

#### Publish messages
  - Use gcloud to publish messages to the topic

#### View messages
  - `python subscrier.py $GOOGLE_CLOUD_PROJECT receive <subscription-name>`


## Challenge Lab

  - Create a bucket
    - Set Region `gcloud config set compute/region "REGION"`
    - `gsutil mb gs://<bucket-name>`
  - Create a Sub/Pub Topic `gcloud pubsub topics create <topic-name>`
  - Create a Cloud Run Function 
    - Make directory
    - Create index.js
    - Create package.json
    - Install dependencies `npm install`
    - Deploy function `gcloud functions deploy <function-name> --gen2 --runtime=nodejs20 --region=REGION --source=. --entry-point=<function-name> --trigger-bucket <bucket-name>`
