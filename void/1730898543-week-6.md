---
id: 1730898543-week-6
aliases:
  - Week 6
tags:
  - google cloud platform
  - course
  - notes
---

# Week 6

# Develop your Google Cloud Network


## Cloud IAM: Qwik Start

## Introduction to [[1730898881-sql|SQL]] for BigQuery and Cloud SQL

#### Exploring the BigQuery console
BigQuery is a fully managed and large scale data warehouse that can be used to store and analyze large amount of data in the best cost-effective way.

- **Menu** > **BigQuery** 
- Starting a project
 - **ADD** > **Start a project by name**  
 - Enter name and **Star** 

#### Working with Cloud SQL
Cloud SQL is a fully managed database service that allow us to control our relational PostgreSQL and MySQL databases in the cloud.
> [!NOTE]
> Cloud SQL manage specific databases engines, BigQuery manages data warehouses, which is a specific type of database that is optimized for analytical workloads or large amount of data

#### Create a Cloud SQL instance
- **Menu** > **SQL** 
- **CREATE INSTANCE** > **MySQL or PostegreSQL**
- Give a id, password, version of db, region and capabilities

#### New queries in cloud SQL
- Using Shell: `gcloud sql connect <INSTANCE_NAME> --user=<USER> --quiet`
- once connected we can use sql syntax
  - Create a new Database: `CREATE DATABASE <DB_NAME>;`
  - Create a table inside a database: `USE <DB_NAME>; CREATE TABLE <TABLE_NAME> ( <COLUMN_NAME> <DATA_TYPE> );`

## Managing Deployments Using Kubernetes Engine

> [!NOTE]
> For this exercise we create a cluster with 3 nodes.

#### Create a deployments
We use yaml files to define the deployments
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth
spec:
  replicas: 1
  selector:
    matchLabels:
      app: auth
  template:
    metadata:
      labels:
        app: auth
        track: stable
    spec:
      containers:
        - name: auth
          image: "kelseyhightower/auth:1.0.0"
          ports:
            - name: http
              containerPort: 80
            - name: health
              containerPort: 81
...
```
- Create a deployment: `kubectl create -f <FILE_NAME>`
- Verify the deployment: `kubectl get deployments`
> When deployment is created, kubernetes will create a ReplicaSet. We can verify the replica with `kubectl get replicasets`
- View the pods: `kubectl get pods`
> [!NOTE] We create two deployments, one for the deploy file itself and other for the service  
- Interact with a service: `kubectl get services <service-name>`

#### Scale a deployment
For scaling a deployment we update the spec.replicas field on the yaml file
- `kubectl scale deployment <DEPLOYMENT_NAME> --replicas=<NUM_REPLICAS> `

#### Rolling updates
We can updating images to a new version, when a deployment is updated it create a new ReplicaSet and slowly increase the number of replicas in the new Set and decrease the number in the old Set.
![Rolling Updates](/file/rolling-updates.png) 
- Update a deployment: `kubectl edit deployment <DEPLOYMENT_NAME>`
- Change the image version: `spec.template.spec.containers.image: <NEW_IMAGE>`
- We can pause the rolling update: `kubectl rollout pause deployment <DEPLOYMENT_NAME>`
- Or resume it: `kubectl rollout resume deployment <DEPLOYMENT_NAME>`
- Roll back and update: `kubectl rollout undo <DEPLOYMENT_NAME>`

#### Canary deployments
Canary deployments allow to release a new version of a service into a subset of users to test it before the complete release.
![Canary Deployments](/files/canary-deployment.png) 

- Canary deployment file:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-canary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: hello
  template:
    metadata:
      labels:
        app: hello
        track: canary
        # Use ver 2.0.0 so it matches version on service selector
        version: 2.0.0
    spec:
      containers:
        - name: hello
          image: kelseyhightower/hello:2.0.0
          ports:
            - name: http
              containerPort: 80
            - name: health
              containerPort: 81
...
```
- Create a canary deployment: `kubectl create -f <FILE_NAME>`
> We have two deployments of the service, one a normal and a canary version
> Both deployments will match pods in both the prod and canary deployment, but canary have fewer number of pods, so it will be visible to fewer users

##### Session affinity
Each request sent to de server had a change to be served by the canary deployment. This doest not ensure that a user didnt get served by the canary, so can create a problem when we have an ui feature that can confuse to users that receive that feature one time and then not.

With session affinity the same user wil always be served by the same version.

To do this we change the service file to:
```yaml
kind: Service
apiVersion: v1
metadata:
  name: "hello"
spec:
  sessionAffinity: ClientIP
  selector:
    app: "hello"
  ports:
    - protocol: "TCP"
      port: 80
      targetPort: 80
```
Setting sessionAffinity to ClientIP will make sure that the same user will always be served by the same version.

#### Blue-Green deployments
There are times where we need to modify a load balancer to point to a new version only when that version is fully deployed, in this cases we use the blue-green deployments. Kubernetes create two separate deployments. This have a downside, we will need at least 2x resources in our cluster.

![Blue-Green Deployments](/files/blue-green-deployments.png) 

We create a new green deployment, the blue deployment is that same deployment but with a different image version.

- green deployment file:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-green
spec:
  replicas: 3
  selector:
    matchLabels:
      app: hello
  template:
    metadata:
      labels:
        app: hello
        track: stable
        version: 2.0.0
    spec:
      containers:
        - name: hello
          image: kelseyhightower/hello:2.0.0
          ports:
            - name: http
              containerPort: 80
            - name: health
              containerPort: 81
          resources:
            limits:
              cpu: 0.2
              memory: 10Mi
          livenessProbe:
            httpGet:
              path: /healthz
              port: 81
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 15
            timeoutSeconds: 5
          readinessProbe:
            httpGet:
              path: /readiness
              port: 81
              scheme: HTTP
            initialDelaySeconds: 5
            timeoutSeconds: 1
```
- Create the deployment

> [!NOTE]
> Investigate more about green blue deployments



